<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="MimicGait">
  <meta property="og:title" content="MimicGait"/>
  <meta property="og:description" content="MimicGait WACV 2025"/>
  <meta property="og:url" content="https://ayush-00.github.io/mimicgait-website"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/Main_cropped.png"/>
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="MimicGait">
  <meta name="twitter:description" content="MimicGait WACV 2025">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/Main_cropped.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>MimicGait WACV 2025</title>
  <link rel="icon" type="image/x-icon" href="static/images/Main_cropped.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">MimicGait: A Model Agnostic approach for Occluded Gait Recognition using Correlational Knowledge Distillation</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://ayush-00.github.io/" target="_blank">Ayush Gupta</a>,</span>
                <span class="author-block">
                  <a href="https://engineering.jhu.edu/faculty/rama-chellappa/" target="_blank">Rama Chellappa</a></span>
                  <!-- <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Third Author</a>
                  </span> -->
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Johns Hopkins University<br>WACV 2025</span>
                    <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="static/pdfs/mimicgait.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="static/pdfs/mimicgait_supplementary.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/Ayush-00/mimicgait" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2501.15666" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        Enter your video here, below:
        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section> -->
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Gait recognition is an important biometric technique over large distances. State-of-the-art gait recognition systems perform very well in controlled environments at close range. Recently, there has been an increased interest in gait recognition in the wild prompted by the collection of outdoor, more challenging datasets containing variations in terms of illumination, pitch angles and distances. An important problem in these environments is that of occlusion, where the subject is partially blocked from camera view. 
            While important, this problem has received little attention. Thus, we propose <strong>MimicGait</strong>, a <em>model-agnostic</em> approach for gait recognition in the presence of occlusions. We train the network using a <em>multi-instance correlational distillation loss</em> to capture both inter-sequence and intra-sequence correlations in the occluded gait patterns of a subject, utilizing an auxiliary Visibility Estimation Network to guide the training of the proposed mimic network. We demonstrate the effectiveness of our approach on challenging real-world datasets like GREW, Gait3D and BRIAR.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item has-text-centered">
          <!-- Your image here -->
          <img src="static/images/BRIAR_more_examples.png" alt="RGB examples"/>
          <h2 class="subtitle has-text-centered">
            Sample RGB images from the BRIAR dataset.
          </h2>
        </div>
        <div class="item has-text-centered">
          <!-- Your image here -->
          <img src="static/images/synthetic_occ.png" alt="synthetic occ"/>
          <h2 class="subtitle has-text-centered">
            Occluded examples of silhouettes from GREW dataset.
          </h2>
        </div>
        <!-- <div class="item has-text-centered">
          <img src="static/images/carousel3.jpg" alt="MY ALT TEXT"/>
          <h2 class="subtitle has-text-centered">
            Third image description.
          </h2>
        </div>
        <div class="item has-text-centered">
          <img src="static/images/carousel4.jpg" alt="MY ALT TEXT"/>
          <h2 class="subtitle has-text-centered">
            Fourth image description.
          </h2>
        </div> -->
      </div>
    </div>
  </div>
</section>
</div>
</section>
<!-- End image carousel -->





<!-- Overview section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <h2 class="title is-3 has-text-centered">Overview</h2>
        <figure class="image">
          <img src="static/images/Main_cropped.png" alt="main methodology figure">
        </figure>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-full">
        
        <p class="has-text-justified">
            We try to learn the correlations between the motion of different body parts through our approach, so that when some body parts are missing, we are able to utilize the observable motion to extract gait features even from the occluded body.
            We train a 'mimic network' to replicate the behavior of a teacher model that has been trained on unoccluded gait sequences to generate ideal gait features. The mimic network is designed to handle occluded sequences by learning from the predictions of the teacher model. 
            This is achieved through a process called correlational knowledge distillation, where the mimic network is trained to capture both inter-sequence and intra-sequence correlations in the occluded gait patterns. The auxiliary Visibility Estimation Network helps guide the training by providing visibility scores for the occluded regions, ensuring that the mimic network focuses on the important parts of the input.
        </p>
      </div>
    </div>
  </div>
</section>
<!-- End Text and Image Section -->







<!-- Text and Image Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <h2 class="title is-3 has-text-centered">Synthetic occlusions</h2>
        <figure class="image">
          <img src="static/images/synthetic_occ.png" alt="Synthetic occlusions">
        </figure>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-full">
        
        <p class="has-text-justified">
            Occlusions can be classified as consistent (static) or dynamic (changing). Consistent occlusions occur due to obstacles like sidewalks or bad camera angles, while dynamic occlusions happen when objects or people temporarily block the subject.

            We simulate both types by placing stationary or moving black patches on input frames. Consistent occlusions remove the top, bottom, or middle part of the frame. We focus on top and bottom occlusions in our main results and evaluate generalizability with middle and dynamic occlusions.

            During training and evaluation, occlusions are introduced randomly, covering 40%-60% of the frame. More details are in the supplementary material.
        </p>
      </div>
    </div>
  </div>
</section>
<!-- End Text and Image Section -->


<!-- Evaluation carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3 has-text-centered">Evaluation</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item has-text-centered">
          <!-- Your image here -->
          <img src="static/images/MimicGait WACV 2025-Probe gallery matching visualize.drawio.png" alt="RGB examples"/>
          <h2 class="subtitle has-text-centered">
            Rank-Retrieval metric.
          </h2>
        </div>
        <div class="item has-text-centered">
          <!-- Your image here -->
          <img src="static/images/MimicGait_RP_visualization.png" alt="synthetic occ"/>
          <h2 class="subtitle has-text-centered">
            Relative performance (RP) metric.
          </h2>
        </div>
        <div class="item has-text-centered">
          <img src="static/images/Generalizability Adaptability.png" alt="MY ALT TEXT"/>
          <h2 class="subtitle has-text-centered">
            Generalizability and Adaptability tests on new occlusion types.
          </h2>
        </div>
      </div>
      <div class="content has-text-justified">
        <p>
          Our evaluation consists of two metrics: Rank-retrieval accuracy and our new proposed metric Relative Performance (RP).
          Rank-retrieval is an absolute measure of performance, which might be affected by factors like strength of backbone. However, we want to evaluate a model-agnostic approach (like MimicGait), and the evaluation should not be affected by the strength of the backbone. Hence, we normalize rank-retrieval accuracy by the strength of the backbone, and call it RP.
        </p>
        <p>
          We also evaluate the generalizability and adaptability of our approach by testing on new occlusion types like middle occlusions and dynamic occlusions. We show that our approach is able to generalize to new occlusion types and is able to also able to adapt to new occlusions.
        </p>
      </div>
    </div>
  </div>
</section>
<!-- End image carousel -->


<!-- Ablations section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <h2 class="title is-3 has-text-centered">Ablations</h2>
        <figure class="image">
            <img src="static/images/ablations.png" alt="Ablations" style="width: 50%; display: block; margin-left: auto; margin-right: auto;">
        </figure>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-full">
        <p class="has-text-justified">
            We perform ablation studies on the proposed approach, to test the importance of the individual components - the mimic network, and the two proxy tasks which the visibility estimation network is trained on. We find that removing the visibility estimation network leads to a significant drop in performance, highlighting its importance in guiding the mimic network. Additionally, we observe that training the visibility estimation network on both proxy tasks results in better performance compared to training on a single task.
        </p>
      </div>
    </div>
  </div>


<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <!-- Youtube embed code here -->
            <iframe width="560" height="315" src="https://www.youtube.com/embed/ynuN_tUorvk" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
        
            <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
           
            <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            
            <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->






<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/poster.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
        @inproceedings{gupta2025wacv,
          title={MimicGait: A Model Agnostic approach for Occluded Gait Recognition using Correlational Knowledge Distillation},
          author={Ayush Gupta and Rama Chellappa},
          booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
          year={2025}
        }
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
